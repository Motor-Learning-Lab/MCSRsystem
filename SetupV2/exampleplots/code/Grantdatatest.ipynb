{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kineticstoolkit.lab as ktk\n",
    "import pandas as pd\n",
    "# Set an interactive backend, not required if already enabled in Spyder\n",
    "%matplotlib qt5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from pyopls import OPLS\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneOut\n",
    "from sklearn.metrics import r2_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file to store the early data\n",
    "Subejct01_alljoints_path = os.path.join('C:/Users/86153/Desktop/MCSRsystem/SetupV2/exampleplots/', \"Subejct01_all_joints_df.csv\")\n",
    "# Save the all_fish_df to the CSV file\n",
    "Subject01_alljoints_data = pd.read_csv(Subejct01_alljoints_path)\n",
    "Subejct01_rotation_path = os.path.join('C:/Users/86153/Desktop/MCSRsystem/SetupV2/exampleplots/', \"Subejct01_angerror_df.csv\")\n",
    "Subject01_rotation_angles= pd.read_csv(Subejct01_rotation_path)\n",
    "\n",
    "\n",
    "# Define the path to the CSV file to store the early data\n",
    "Subejct02_alljoints_path = os.path.join('C:/Users/86153/Desktop/MCSRsystem/SetupV2/exampleplots/', \"Subejct02_all_joints_df.csv\")\n",
    "# Save the all_fish_df to the CSV file\n",
    "Subject02_alljoints_data = pd.read_csv(Subejct02_alljoints_path)\n",
    "Subejct02_rotation_path = os.path.join('C:/Users/86153/Desktop/MCSRsystem/SetupV2/exampleplots/', \"Subejct02_angerror_df.csv\")\n",
    "Subject02_rotation_angles= pd.read_csv(Subejct02_rotation_path)\n",
    "\n",
    "\n",
    "# Define the path to the CSV file to store the early data\n",
    "Subejct03_alljoints_path = os.path.join('C:/Users/86153/Desktop/MCSRsystem/SetupV2/exampleplots/', \"Subejct03_all_joints_df.csv\")\n",
    "# Save the all_fish_df to the CSV file\n",
    "Subject03_alljoints_data = pd.read_csv(Subejct03_alljoints_path)\n",
    "Subejct03_rotation_path = os.path.join('C:/Users/86153/Desktop/MCSRsystem/SetupV2/exampleplots/', \"Subejct03_angerror_df.csv\")\n",
    "Subject03_rotation_angles= pd.read_csv(Subejct03_rotation_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPLS input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the subject ID dynamically\n",
    "subject_id = \"Subject03\"\n",
    "\n",
    "# Load data dynamically for the specified subject\n",
    "alljoints_data = globals()[f\"{subject_id}_alljoints_data\"]\n",
    "rotation_angles = globals()[f\"{subject_id}_rotation_angles\"]\n",
    "\n",
    "# Extract early and late rotation data\n",
    "Rotation_data_early = alljoints_data[(alljoints_data['Trial ID'] >= 11) & (alljoints_data['Trial ID'] <= 110)]\n",
    "Rotation_data_late = alljoints_data[(alljoints_data['Trial ID'] >= 211) & (alljoints_data['Trial ID'] <= 310)]\n",
    "\n",
    "# Select elements for early and late angle errors\n",
    "early_angerror = rotation_angles[10:110]\n",
    "late_angerror = rotation_angles[210:310]\n",
    "\n",
    "\n",
    "OPLS_NoP = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create pivot tables\n",
    "early_value_data = Rotation_data_early.pivot_table(index='Trial ID', columns='Angle Name', values='Value')\n",
    "early_euler_data = Rotation_data_early.pivot_table(index='Trial ID', columns='Angle Name', values='Euler')\n",
    "\n",
    "# Step 2: Combine the two DataFrames into one\n",
    "early_data = pd.concat([early_value_data, early_euler_data], axis=1)\n",
    "\n",
    "# Step 3: Rename the columns for clarity\n",
    "# Create new column names for Value and Euler\n",
    "value_columns = [f\"{angle}_Value\" for angle in early_value_data.columns]\n",
    "euler_columns = [f\"{angle}_Euler\" for angle in early_euler_data.columns]\n",
    "\n",
    "# Assign the new column names\n",
    "early_data.columns = value_columns + euler_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create pivot tables\n",
    "late_value_data = Rotation_data_late.pivot_table(index='Trial ID', columns='Angle Name', values='Value')\n",
    "late_euler_data = Rotation_data_late.pivot_table(index='Trial ID', columns='Angle Name', values='Euler')\n",
    "\n",
    "# Step 2: Combine the two DataFrames into one\n",
    "late_data = pd.concat([late_value_data, late_euler_data], axis=1)\n",
    "\n",
    "# Step 3: Rename the columns for clarity\n",
    "# Create new column names for Value and Euler\n",
    "value_columns = [f\"{angle}_Value\" for angle in late_value_data.columns]\n",
    "euler_columns = [f\"{angle}_Euler\" for angle in late_euler_data.columns]\n",
    "\n",
    "# Assign the new column names\n",
    "late_data.columns = value_columns + euler_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.linalg import svd\n",
    "\n",
    "def effective_pseudo_determinant(matrix, threshold=1e-10):\n",
    "    \"\"\"\n",
    "    Calculate the pseudo-determinant of a matrix based on its effective rank.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix (np.ndarray): The input matrix.\n",
    "    threshold (float): Threshold for considering singular values as non-zero.\n",
    "    \n",
    "    Returns:\n",
    "    float: The pseudo-determinant based on effective rank.\n",
    "    \"\"\"\n",
    "    # Compute singular values\n",
    "    u, s, vh = svd(matrix)\n",
    "    \n",
    "    # Filter singular values by threshold to determine effective rank\n",
    "    effective_singular_values = s[s > threshold]\n",
    "    \n",
    "    # Compute pseudo-determinant as the product of these singular values\n",
    "    pseudo_det = np.prod(effective_singular_values)\n",
    "    \n",
    "    return pseudo_det\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does early_data contain NaN values? True\n",
      "Rows containing NaN values:\n",
      "          Pelvis[0] max vel_Value  Pelvis[0] move onset_Value  \\\n",
      "Trial ID                                                        \n",
      "52                       3.031959                   -0.202995   \n",
      "53                       3.833283                    0.166815   \n",
      "56                            NaN                   -1.870524   \n",
      "97                            NaN                   -0.421638   \n",
      "104                           NaN                   -4.298876   \n",
      "\n",
      "          Pelvis[1] max vel_Value  Pelvis[1] move onset_Value  \\\n",
      "Trial ID                                                        \n",
      "52                      10.656412                    3.463677   \n",
      "53                      -2.765145                    0.670077   \n",
      "56                            NaN                   -0.825992   \n",
      "97                            NaN                   -0.041723   \n",
      "104                           NaN                   -1.857588   \n",
      "\n",
      "          Pelvis[2] max vel_Value  Pelvis[2] move onset_Value  \\\n",
      "Trial ID                                                        \n",
      "52                      13.867451                   -1.215629   \n",
      "53                      -4.597596                   -3.542821   \n",
      "56                            NaN                   -5.483545   \n",
      "97                            NaN                    0.622279   \n",
      "104                           NaN                    3.287097   \n",
      "\n",
      "          R_Arm[1] max vel_Value  R_Arm[1] move onset_Value  \\\n",
      "Trial ID                                                      \n",
      "52                     72.576645                  -9.914676   \n",
      "53                     16.241967                  -1.170002   \n",
      "56                    -25.816077                   4.468313   \n",
      "97                    -27.535567                   2.060893   \n",
      "104                   -18.996633                   7.546459   \n",
      "\n",
      "          R_Arm[2] max vel_Value  R_Arm[2] move onset_Value  ...  \\\n",
      "Trial ID                                                     ...   \n",
      "52                      9.997688                   2.227815  ...   \n",
      "53                      3.027553                   2.120923  ...   \n",
      "56                     20.981387                  12.270708  ...   \n",
      "97                    -17.585738                  -0.268684  ...   \n",
      "104                     5.772299                  -2.307126  ...   \n",
      "\n",
      "          R_Forearm[2] max vel_Euler  R_Forearm[2] move onset_Euler  \\\n",
      "Trial ID                                                              \n",
      "52                        -53.281998                     -50.711864   \n",
      "53                        -36.919177                     -37.040779   \n",
      "56                        -75.782315                     -75.587357   \n",
      "97                        -76.020706                     -75.383199   \n",
      "104                       -76.762858                     -76.937537   \n",
      "\n",
      "          R_Hand[1] max vel_Euler  R_Hand[1] move onset_Euler  \\\n",
      "Trial ID                                                        \n",
      "52                            NaN                         NaN   \n",
      "53                            NaN                         NaN   \n",
      "56                     -10.895634                  -11.163359   \n",
      "97                     -33.294172                  -33.629465   \n",
      "104                    -33.310757                  -34.427669   \n",
      "\n",
      "          Thorax[0] max vel_Euler  Thorax[0] move onset_Euler  \\\n",
      "Trial ID                                                        \n",
      "52                      -2.065359                   -4.803779   \n",
      "53                      -6.347270                   -5.290708   \n",
      "56                            NaN                   18.790078   \n",
      "97                     -12.227888                   -7.351874   \n",
      "104                           NaN                   -8.310152   \n",
      "\n",
      "          Thorax[1] max vel_Euler  Thorax[1] move onset_Euler  \\\n",
      "Trial ID                                                        \n",
      "52                      77.285665                   77.212359   \n",
      "53                      77.436939                   77.407997   \n",
      "56                            NaN                   77.859174   \n",
      "97                      76.994273                   77.441411   \n",
      "104                           NaN                   78.848895   \n",
      "\n",
      "          Thorax[2] max vel_Euler  Thorax[2] move onset_Euler  \n",
      "Trial ID                                                       \n",
      "52                      -1.761148                    1.180914  \n",
      "53                       2.971299                    1.611438  \n",
      "56                            NaN                  -18.728875  \n",
      "97                       2.687082                   -2.310239  \n",
      "104                           NaN                    3.362803  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "has_nan = early_data.isna().any().any()\n",
    "print(\"Does early_data contain NaN values?\", has_nan)\n",
    "nan_rows = early_data[early_data.isna().any(axis=1)]\n",
    "print(\"Rows containing NaN values:\")\n",
    "print(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward-fill rows with NaNs based on the previous row\n",
    "early_data = early_data.ffill(axis=0)\n",
    "\n",
    "# Check if there are still any NaNs remaining in the first row\n",
    "# If the first row has NaNs, they will remain as there is no previous row to copy from\n",
    "early_data.iloc[0] = early_data.iloc[0].fillna(early_data.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_cov_matrix = early_data.cov()\n",
    "early_det_value = np.linalg.det(early_cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "opls = OPLS(OPLS_NoP)\n",
    "self = opls.fit(early_data,early_angerror)\n",
    "TP = self.T_ortho_ @ np.transpose(self.P_ortho_)\n",
    "early_reduandant_cov_matrix = np.cov(TP)\n",
    "early_reduandant_det_value = np.linalg.det(early_reduandant_cov_matrix)\n",
    "Z = opls.transform(early_data)\n",
    "\n",
    "early_related_cov_matrix = np.cov(Z)\n",
    "early_related_det_value = np.linalg.det(early_related_cov_matrix)\n",
    "pseudo_det = effective_pseudo_determinant(early_reduandant_cov_matrix, threshold=1e-1)\n",
    "pseudo_det_related = effective_pseudo_determinant(early_related_cov_matrix, threshold=1e-1)\n",
    "pseudo_efficiency  = pseudo_det/pseudo_det_related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does late_data contain NaN values? True\n",
      "Rows containing NaN values:\n",
      "          Pelvis[0] max vel_Value  Pelvis[0] move onset_Value  \\\n",
      "Trial ID                                                        \n",
      "291                           NaN                    3.820806   \n",
      "\n",
      "          Pelvis[1] max vel_Value  Pelvis[1] move onset_Value  \\\n",
      "Trial ID                                                        \n",
      "291                           NaN                   30.314916   \n",
      "\n",
      "          Pelvis[2] max vel_Value  Pelvis[2] move onset_Value  \\\n",
      "Trial ID                                                        \n",
      "291                           NaN                   -3.839345   \n",
      "\n",
      "          R_Arm[1] max vel_Value  R_Arm[1] move onset_Value  \\\n",
      "Trial ID                                                      \n",
      "291                    29.657539                   4.863712   \n",
      "\n",
      "          R_Arm[2] max vel_Value  R_Arm[2] move onset_Value  ...  \\\n",
      "Trial ID                                                     ...   \n",
      "291                   -17.646446                   4.827952  ...   \n",
      "\n",
      "          R_Forearm[2] max vel_Euler  R_Forearm[2] move onset_Euler  \\\n",
      "Trial ID                                                              \n",
      "291                       -86.862681                     -90.914641   \n",
      "\n",
      "          R_Hand[1] max vel_Euler  R_Hand[1] move onset_Euler  \\\n",
      "Trial ID                                                        \n",
      "291                    -37.302198                   -39.90724   \n",
      "\n",
      "          Thorax[0] max vel_Euler  Thorax[0] move onset_Euler  \\\n",
      "Trial ID                                                        \n",
      "291                     31.796541                   26.253287   \n",
      "\n",
      "          Thorax[1] max vel_Euler  Thorax[1] move onset_Euler  \\\n",
      "Trial ID                                                        \n",
      "291                     75.931571                   77.458377   \n",
      "\n",
      "          Thorax[2] max vel_Euler  Thorax[2] move onset_Euler  \n",
      "Trial ID                                                       \n",
      "291                     -27.95514                  -23.429194  \n",
      "\n",
      "[1 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "has_nan = late_data.isna().any().any()\n",
    "print(\"Does late_data contain NaN values?\", has_nan)\n",
    "nan_rows = late_data[late_data.isna().any(axis=1)]\n",
    "print(\"Rows containing NaN values:\")\n",
    "print(nan_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward-fill rows with NaNs based on the previous row\n",
    "late_data = late_data.ffill(axis=0)\n",
    "\n",
    "# Check if there are still any NaNs remaining in the first row\n",
    "# If the first row has NaNs, they will remain as there is no previous row to copy from\n",
    "late_data.iloc[0] = late_data.iloc[0].fillna(late_data.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_cov_matrix = late_data.cov()\n",
    "late_det_value = np.linalg.det(late_cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "opls = OPLS(OPLS_NoP)\n",
    "\n",
    "self = opls.fit(late_data,late_angerror)\n",
    "TP = self.T_ortho_ @ np.transpose(self.P_ortho_)\n",
    "late_reduandant_cov_matrix = np.cov(TP)\n",
    "late_reduandant_det_value = np.linalg.det(early_reduandant_cov_matrix)\n",
    "Z = opls.transform(late_data)\n",
    "\n",
    "late_related_cov_matrix = np.cov(Z)\n",
    "late_related_det_value = np.linalg.det(late_related_cov_matrix)\n",
    "pseudo_det_late = effective_pseudo_determinant(late_reduandant_cov_matrix, threshold=1e-1)\n",
    "pseudo_det_related_late = effective_pseudo_determinant(late_related_cov_matrix, threshold=1e-1)\n",
    "pseudo_efficiency_late  = pseudo_det_late/pseudo_det_related_late\n",
    "\n",
    "late_related_cov_matrix = np.cov(Z)\n",
    "late_related_det_value = np.linalg.det(late_related_cov_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movement complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PCs needed to explain 90% of variance: 7\n",
      "Number of PCs that explain more than 1% of variance: 11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Perform PCA\n",
    "pca_early = PCA()\n",
    "pca_early.fit(early_data)\n",
    "\n",
    "# Calculate explained variance ratio for each component\n",
    "early_explained_variance_ratio = pca_early.explained_variance_ratio_\n",
    "\n",
    "# Determine number of PCs needed to explain 90% of variance\n",
    "early_cumulative_variance = np.cumsum(early_explained_variance_ratio)\n",
    "early_num_pcs_90 = np.argmax(early_cumulative_variance >= 0.90) + 1\n",
    "\n",
    "# Count how many PCs explain more than 1% of variance\n",
    "early_num_pcs_above_1_percent = np.sum(early_explained_variance_ratio > 0.01)\n",
    "\n",
    "print(f\"Number of PCs needed to explain 90% of variance: {early_num_pcs_90}\")\n",
    "print(f\"Number of PCs that explain more than 1% of variance: {early_num_pcs_above_1_percent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PCs needed to explain 90% of variance: 9\n",
      "Number of PCs that explain more than 1% of variance: 13\n"
     ]
    }
   ],
   "source": [
    "# Perform PCA\n",
    "pca_late = PCA()\n",
    "pca_late.fit(late_data)\n",
    "\n",
    "# Calculate explained variance ratio for each component\n",
    "late_explained_variance_ratio = pca_late.explained_variance_ratio_\n",
    "\n",
    "# Determine number of PCs needed to explain 90% of variance\n",
    "late_cumulative_variance = np.cumsum(late_explained_variance_ratio)\n",
    "late_num_pcs_90 = np.argmax(late_cumulative_variance >= 0.90) + 1\n",
    "\n",
    "# Count how many PCs explain more than 1% of variance\n",
    "late_num_pcs_above_1_percent = np.sum(late_explained_variance_ratio > 0.01)\n",
    "\n",
    "print(f\"Number of PCs needed to explain 90% of variance: {late_num_pcs_90}\")\n",
    "print(f\"Number of PCs that explain more than 1% of variance: {late_num_pcs_above_1_percent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming early_angerror and late_angerror are arrays or lists with 100 elements each.\n",
    "# Replace `x_values` with your actual x-coordinates if they are defined. If you just want indices as x-values:\n",
    "x_values = range(100)\n",
    "\n",
    "# Scatter plot for early_angerror\n",
    "plt.scatter(x_values, early_angerror, label=\"Early Angle Error\", color='blue')\n",
    "\n",
    "# Scatter plot for late_angerror\n",
    "plt.scatter(x_values, late_angerror, label=\"Late Angle Error\", color='red')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Angle Error\")\n",
    "plt.title(\"Scatter Plot of Early and Late Angle Errors\")\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Efficiency in the early rotation using Pseudo-Determinant : 370617288.652938\n",
      "The Efficiency in the late rotation using Pseudo-Determinant : 4425568984.258379\n",
      "Number of PCs needed to explain 90% of variance - early: 7\n",
      "Number of PCs that explain more than 1% of variance - early: 11\n",
      "Number of PCs needed to explain 90% of variance - late: 9\n",
      "Number of PCs that explain more than 1% of variance - late: 13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"The Efficiency in the early rotation using Pseudo-Determinant : {pseudo_efficiency}\")\n",
    "print(f\"The Efficiency in the late rotation using Pseudo-Determinant : {pseudo_efficiency_late}\")\n",
    "\n",
    "print(f\"Number of PCs needed to explain 90% of variance - early: {early_num_pcs_90}\")\n",
    "print(f\"Number of PCs that explain more than 1% of variance - early: {early_num_pcs_above_1_percent}\")\n",
    "\n",
    "print(f\"Number of PCs needed to explain 90% of variance - late: {late_num_pcs_90}\")\n",
    "print(f\"Number of PCs that explain more than 1% of variance - late: {late_num_pcs_above_1_percent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:/Users/86153/Desktop/MCSRsystem/SetupV2/exampleplots/data/Subject03_rotation_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "# Create a dictionary with the parameters, including subject_id\n",
    "data = {\n",
    "    'subject_id': subject_id,\n",
    "    'early_det_value': early_det_value,\n",
    "    'late_det_value': late_det_value,\n",
    "    'pseudo_efficiency': pseudo_efficiency,\n",
    "    'pseudo_efficiency_late': pseudo_efficiency_late,\n",
    "    'early_num_pcs_90': early_num_pcs_90,\n",
    "    'early_num_pcs_above_1_percent': early_num_pcs_above_1_percent,\n",
    "    'late_num_pcs_90': late_num_pcs_90,\n",
    "    'late_num_pcs_above_1_percent': late_num_pcs_above_1_percent\n",
    "}\n",
    "\n",
    "# Define the filename\n",
    "filename = f'C:/Users/86153/Desktop/MCSRsystem/SetupV2/exampleplots/data/{subject_id}_rotation_analysis.csv'\n",
    "\n",
    "# Write the data to the CSV file\n",
    "with open(filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(data.keys())  # Write header\n",
    "    writer.writerow(data.values())  # Write values\n",
    "\n",
    "print(f\"Data saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compenents test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of input values for OPLS\n",
    "opls_inputs = range(5, 41)\n",
    "\n",
    "# Empty lists to store the results for each opls input\n",
    "early_pseudo_det_values = []\n",
    "late_pseudo_det_values = []\n",
    "early_efficiency_values = []\n",
    "late_efficiency_values = []\n",
    "\n",
    "# Loop through each opls input value\n",
    "for n_components in opls_inputs:\n",
    "    # Initialize and fit OPLS model for early data\n",
    "    opls_early = OPLS(n_components)\n",
    "    self_early = opls_early.fit(early_data, early_angerror)\n",
    "    TP_early = self_early.T_ortho_ @ np.transpose(self_early.P_ortho_)\n",
    "    early_redundant_cov_matrix = np.cov(TP_early)\n",
    "    \n",
    "    Z_early = opls_early.transform(early_data)\n",
    "    early_related_cov_matrix = np.cov(Z_early)\n",
    "    \n",
    "    # Compute pseudo-determinants and efficiency for early data\n",
    "    pseudo_det_early_redundant = effective_pseudo_determinant(early_redundant_cov_matrix, threshold=1e-1)\n",
    "    pseudo_det_early_related = effective_pseudo_determinant(early_related_cov_matrix, threshold=1e-1)\n",
    "    pseudo_efficiency_early = pseudo_det_early_redundant / pseudo_det_early_related\n",
    "    pseudo_early_cov_matrix = effective_pseudo_determinant(early_cov_matrix, threshold=1e-1)\n",
    "    \n",
    "    # Store the results for early data\n",
    "    early_efficiency_values.append(pseudo_efficiency_early)\n",
    "\n",
    "    # Initialize and fit OPLS model for late data\n",
    "    opls_late = OPLS(n_components)\n",
    "    self_late = opls_late.fit(late_data, late_angerror)\n",
    "    TP_late = self_late.T_ortho_ @ np.transpose(self_late.P_ortho_)\n",
    "    late_redundant_cov_matrix = np.cov(TP_late)\n",
    "    \n",
    "    Z_late = opls_late.transform(late_data)\n",
    "    late_related_cov_matrix = np.cov(Z_late)\n",
    "    \n",
    "    # Compute pseudo-determinants and efficiency for late data\n",
    "    pseudo_det_late_redundant = effective_pseudo_determinant(late_redundant_cov_matrix, threshold=1e-1)\n",
    "    pseudo_det_late_related = effective_pseudo_determinant(late_related_cov_matrix, threshold=1e-1)\n",
    "    pseudo_efficiency_late = pseudo_det_late_redundant / pseudo_det_late_related\n",
    "    pseudo_late_cov_matrix = effective_pseudo_determinant(late_cov_matrix, threshold=1e-1)\n",
    "    \n",
    "    # Store the results for late data\n",
    "    late_efficiency_values.append(pseudo_efficiency_late)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the efficiencies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(opls_inputs, early_efficiency_values, label=\"Early Efficiency\", marker='o')\n",
    "plt.plot(opls_inputs, late_efficiency_values, label=\"Late Efficiency\", marker='s')\n",
    "\n",
    "# Labeling the plot\n",
    "plt.xlabel(\"OPLS Components\")\n",
    "plt.ylabel(\"Efficiency\")\n",
    "plt.title(\"Efficiency vs. OPLS Components\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
