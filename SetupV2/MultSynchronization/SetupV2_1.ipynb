{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kineticstoolkit.lab as ktk\n",
    "import pandas as pd\n",
    "# Set an interactive backend, not required if already enabled in Spyder\n",
    "%matplotlib qt5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative path to the CSV file\n",
    "Subject01_SRdata_path = r\"../SRrawdata/Subject01/111_f_2024-11-04_13h07.58.818.csv\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "Subject01_SRdata = pd.read_csv(Subject01_SRdata_path)\n",
    "# Read the C3D fiel into a Dictionary\n",
    "Subject01_MCdata_path = r\"../MCrawdata/Subject01/Ex_V2_S0001.c3d\"\n",
    "\n",
    "# Read the C3D fiel into a Dictionary\n",
    "Subject01_MCdata = ktk.read_c3d(Subject01_MCdata_path)['Points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Relative path to the CSV file\n",
    "# Subject01_SRdata_path = r\"../SRrawdata/Subject02/222_f_2024-11-09_17h21.29.442.csv\"\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# Subject01_SRdata = pd.read_csv(Subject01_SRdata_path)\n",
    "# # Read the C3D file into a Dictionary\n",
    "# Subject01_MCdata_path = r\"../MCrawdata/Subject02/Ex_V2_S0002.c3d\"\n",
    "\n",
    "# # Read the C3D fiel into a Dictionary\n",
    "# Subject01_MCdata = ktk.read_c3d(Subject01_MCdata_path)['Points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Relative path to the CSV file\n",
    "# Subject01_SRdata_path = r\"../SRrawdata/Subject03/333_f_2024-11-09_19h07.57.263.csv\"\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# Subject01_SRdata = pd.read_csv(Subject01_SRdata_path)\n",
    "# # Read the C3D file into a Dictionary\n",
    "# Subject01_MCdata_path = r\"../MCrawdata/Subject03/Ex_V2_S0003.c3d\"\n",
    "\n",
    "# # Read the C3D fiel into a Dictionary\n",
    "# Subject01_MCdata = ktk.read_c3d(Subject01_MCdata_path)['Points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "interconnections = dict()\n",
    "\n",
    "interconnections[\"Hand\"] = {\n",
    "    \"Color\": (0, 0.5, 1),  # In (R,G,B) format (here, greenish blue)\n",
    "    \"Links\": [  # List of lines that span lists of markers\n",
    "        [\"R_L_H\", \"R_M_H\", \"R_M_W\", \"R_L_W\"],\n",
    "        ['R_L_H','R_L_W']\n",
    "    ],\n",
    "}\n",
    "\n",
    "interconnections[\"Thorax\"] = {\n",
    "    \"Color\": (0.5, 1, 0.5),\n",
    "    \"Links\": [\n",
    "        [\"R_S\", \"L_S\",\"Back\"],\n",
    "        ['R_S','Back']\n",
    "    ],\n",
    "}\n",
    "\n",
    "interconnections[\"Belly\"] = {\n",
    "    \"Color\": (0.5, 1, 0.5),\n",
    "    \"Links\": [\n",
    "        [\"R_H\", \"L_H\",\"Back\"],\n",
    "        ['R_H','Back']\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "interconnections[\"Arm\"] = {\n",
    "    \"Color\": (1, 0.5, 1),\n",
    "    \"Links\": [\n",
    "        ['R_L_E', \"R_L_W\",\"R_M_W\",'R_M_E'],\n",
    "        ['R_L_E',\"R_S\",'R_M_E'],\n",
    "        ['R_L_E','R_M_E'],\n",
    "    ],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming SRdata is your DataFrame\n",
    "# Initialize variables to store trial count and start/end times\n",
    "trial_count = 0\n",
    "start_end_times = []\n",
    "\n",
    "# Iterate through each row in the 'moving_mouse.time' column\n",
    "for i, row in Subject01_SRdata['moving_mouse.time'].items():\n",
    "    if pd.notna(row):\n",
    "        # Increment trial count\n",
    "        trial_count += 1\n",
    "        \n",
    "        # Convert the row to a list and get the first and last element\n",
    "        time_series = eval(row)  # Using eval to convert string representation of lists to actual lists\n",
    "        start_time = time_series[0]\n",
    "        end_time = time_series[-1]\n",
    "        \n",
    "        # Store the start and end times\n",
    "        start_end_times.append((start_time, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Subject01_MCdata = Subject01_MCdata.ui_edit_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_expstart = Subject01_MCdata.get_index_at_event('Expstart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First start time\n",
    "first_start_time = start_end_times[0][0]-Subject01_MCdata.time[index_expstart]\n",
    "\n",
    "# Sync all times by subtracting the first start time\n",
    "synced_start_end_times = [(start - first_start_time, end - first_start_time) for start, end in start_end_times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 2))\n",
    "\n",
    "# Plot each event as a line on the timeline\n",
    "for (start, end) in synced_start_end_times:\n",
    "    plt.plot([start, end], [0, 0], marker='|', color='b', linewidth=1)\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.yticks([])  # Hide y-axis labels since we don't need them\n",
    "plt.title(\"Event Timeline\")\n",
    "\n",
    "# Add grid for better visibility\n",
    "plt.grid(True, which='both', axis='x', linestyle='--', linewidth=0.5)\n",
    "\n",
    "Subject01_MCdata.plot(['PEN'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Local corrdinate system\n",
    "\n",
    "### Arm coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(markers):\n",
    "    frames = ktk.TimeSeries(time=markers.time)\n",
    "\n",
    "    # ## Global\n",
    "    # The global coordinate system was recorded with:\n",
    "    #            z up, y forward and x to the right.\n",
    "    # The joint coordinates are in y up, x forward, and z to the right.\n",
    "    # Let's create a frame that captures this.\n",
    "    global_transform = ktk.geometry.create_transforms(\n",
    "        seq=\"xy\", angles=[[-90, -90]], degrees=True\n",
    "    )\n",
    "\n",
    "    # ## pelvis\n",
    "    pelvis_origin = (markers.data[\"R_H\"] + markers.data[\"L_H\"]) / 2\n",
    "    pelvis_z = markers.data[\"L_H\"] - markers.data[\"R_H\"]\n",
    "    pelvis_yz = markers.data[\"Back\"] - pelvis_origin\n",
    "\n",
    "    frames.data[\"Pelvis\"] = ktk.geometry.create_frames(\n",
    "        origin=pelvis_origin, z=pelvis_z, yz=pelvis_yz\n",
    "    )\n",
    "\n",
    "    # ## Thorax\n",
    "    thorax_origin = (markers.data[\"L_S\"] + markers.data[\"R_S\"]) / 2\n",
    "    thorax_z = markers.data[\"L_S\"] - markers.data[\"R_S\"]\n",
    "    thorax_yz = thorax_origin - markers.data[\"Back\"]\n",
    "\n",
    "    frames.data[\"Thorax\"] = ktk.geometry.create_frames(\n",
    "        origin=thorax_origin, z=thorax_z, yz=thorax_yz\n",
    "    )\n",
    "\n",
    "    # ## Upper arms\n",
    "    # ### Right upper arm\n",
    "    r_arm_origin = markers.data[\"R_S\"]\n",
    "    r_arm_y = markers.data[\"R_S\"] -0.5*(markers.data[\"R_L_E\"] + markers.data[\"R_M_E\"]) \n",
    "    r_arm_yz = markers.data[\"R_L_E\"] - markers.data[\"R_M_E\"]\n",
    "\n",
    "    frames.data[\"R_Arm\"] = ktk.geometry.create_frames(\n",
    "        origin=r_arm_origin, y=r_arm_y, yz=r_arm_yz\n",
    "    )\n",
    "\n",
    "\n",
    "    # ## Forearms\n",
    "    # ### Right forearm\n",
    "    r_forearm_origin = markers.data[\"R_M_W\"]\n",
    "    r_forearm_y = 0.5*(markers.data[\"R_L_E\"] + markers.data[\"R_M_E\"])  - 0.5*(markers.data[\"R_L_W\"]+markers.data[\"R_M_W\"])\n",
    "    r_forearm_yz = markers.data[\"R_M_W\"] - markers.data[\"R_L_W\"]\n",
    "\n",
    "    frames.data[\"R_Forearm\"] = ktk.geometry.create_frames(\n",
    "        origin=r_forearm_origin, y=r_forearm_y, yz=r_forearm_yz\n",
    "    )\n",
    "\n",
    "    # ## Hands\n",
    "    # ### Right hand\n",
    "    r_hand_origin = markers.data[\"R_L_W\"]\n",
    "    r_hand_z = markers.data[\"R_L_W\"] - markers.data[\"R_M_W\"]\n",
    "    r_hand_yz = (markers.data[\"R_M_H\"] + markers.data[\"R_L_H\"]) / 2 - 0.5*(markers.data[\"R_L_W\"]+markers.data[\"R_M_W\"])\n",
    "    \n",
    "\n",
    "    frames.data[\"R_Hand\"] = ktk.geometry.create_frames(\n",
    "        origin=r_hand_origin, z=r_hand_z, yz=r_hand_yz\n",
    "    )\n",
    "\n",
    "    return frames, global_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeWarning [c:\\Users\\86153\\anaconda3\\envs\\ktk\\Lib\\site-packages\\kineticstoolkit\\geometry.py:592] invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "framesV2,global_transformV2 = get_frames(Subject01_MCdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homogeneous_angle(frames, global_transform):\n",
    "    homogeneous = ktk.TimeSeries(time=frames.time)\n",
    "\n",
    "    if len(frames.time) == 0:\n",
    "        nan_array = np.full((0, 4, 4), np.nan)\n",
    "        for key in [\n",
    "            \"pelvis\",\n",
    "            \"pelvis_to_thorax\",\n",
    "            \"thorax_to_r_arm\",\n",
    "            \"R_arm_to_forearm\",\n",
    "            \"R_forearm_to_hand\",\n",
    "        ]:\n",
    "            homogeneous.data[key] = nan_array\n",
    "        return homogeneous\n",
    "    try:\n",
    "        homogeneous.data[\"pelvis\"] = ktk.geometry.get_local_coordinates(\n",
    "            frames.data[\"Pelvis\"], global_transform\n",
    "        )\n",
    "        homogeneous.data[\"pelvis_to_thorax\"] = ktk.geometry.get_local_coordinates(\n",
    "            frames.data[\"Thorax\"], frames.data[\"Pelvis\"]\n",
    "        )\n",
    "        homogeneous.data[\"thorax_to_r_arm\"] = ktk.geometry.get_local_coordinates(\n",
    "            frames.data[\"R_Arm\"], frames.data[\"Thorax\"]\n",
    "        )\n",
    "        homogeneous.data[\"R_arm_to_forearm\"] = ktk.geometry.get_local_coordinates(\n",
    "            frames.data[\"R_Forearm\"], frames.data[\"R_Arm\"]\n",
    "        )\n",
    "        homogeneous.data[\"R_forearm_to_hand\"] = ktk.geometry.get_local_coordinates(\n",
    "            frames.data[\"R_Hand\"], frames.data[\"R_Forearm\"]\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "    return homogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeries with attributes:\n",
       "         time: <array of shape (310562,)>\n",
       "         data: <dict with 5 entries>\n",
       "    time_info: {'Unit': 's'}\n",
       "    data_info: {}\n",
       "       events: []"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_homogeneous_angle(framesV2,global_transformV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "homogeneous = ktk.TimeSeries(time=Subject01_MCdata.time)\n",
    "\n",
    "global_transform = ktk.geometry.create_transforms(\n",
    "        seq=\"xy\", angles=[[-90, -90]], degrees=True\n",
    "    )\n",
    "homogeneous.data[\"pelvis\"] = ktk.geometry.get_local_coordinates(\n",
    "    framesV2.data[\"Pelvis\"], global_transform\n",
    ")\n",
    "homogeneous.data[\"pelvis_to_thorax\"] = ktk.geometry.get_local_coordinates(\n",
    "    framesV2.data[\"Thorax\"], framesV2.data[\"Pelvis\"]\n",
    "        )\n",
    "homogeneous.data[\"thorax_to_r_arm\"] = ktk.geometry.get_local_coordinates(\n",
    "    framesV2.data[\"R_Arm\"], framesV2.data[\"Thorax\"]\n",
    "        )\n",
    "homogeneous.data[\"R_arm_to_forearm\"] = ktk.geometry.get_local_coordinates(\n",
    "    framesV2.data[\"R_Forearm\"], framesV2.data[\"R_Arm\"]\n",
    "        )\n",
    "homogeneous.data[\"R_forearm_to_hand\"] = ktk.geometry.get_local_coordinates(\n",
    "            framesV2.data[\"R_Hand\"], framesV2.data[\"R_Forearm\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "euler = ktk.TimeSeries(time=framesV2.time)\n",
    "euler.data[\"Pelvis\"] = ktk.geometry.get_angles(\n",
    "            homogeneous.data[\"pelvis\"], \"ZYZ\", degrees=True\n",
    "        )\n",
    "euler.data[\"Thorax\"] = ktk.geometry.get_angles(\n",
    "            homogeneous.data[\"pelvis_to_thorax\"], \"YZX\", degrees=True\n",
    "        )\n",
    "euler.data[\"R_Arm\"] = ktk.geometry.get_angles(\n",
    "            homogeneous.data[\"thorax_to_r_arm\"], \"YZX\", degrees=True\n",
    "        )\n",
    "euler.data[\"R_Forearm\"] = ktk.geometry.get_angles(\n",
    "            homogeneous.data[\"R_arm_to_forearm\"], \"ZXY\", degrees=True\n",
    "        )\n",
    "euler.data[\"R_Hand\"] = ktk.geometry.get_angles(\n",
    "            homogeneous.data[\"R_forearm_to_hand\"], \"XZY\", degrees=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 2))\n",
    "# # plt.plot(euler.time, euler.data[\"R_Arm\"],label = \"R_Arm\" )\n",
    "# # plt.plot(euler.time, euler.data[\"Thorax\"],label = \"Thorax\" )\n",
    "# # plt.plot(euler.time, euler.data[\"Pelvis\"],label = \"Pelvis\")\n",
    "# plt.plot(euler.time, euler.data[\"R_Forearm\"],label = \"R_Forearm\")\n",
    "# plt.title('Example Angle')\n",
    "\n",
    "# plt.ylabel('deg')\n",
    "# plt.legend()\n",
    "# # plt.ylim(-100,100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeries with attributes:\n",
       "         time: <array of shape (310562,)>\n",
       "         data: <dict with 5 entries>\n",
       "    time_info: {'Unit': 's'}\n",
       "    data_info: {}\n",
       "       events: []"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euler_vels = ktk.filters.deriv(euler)\n",
    "euler_vels.resample(euler.time, kind=\"cubic\", in_place=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(synced_start_end_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.8847459684402572),\n",
       " np.float64(0.6997254914168594),\n",
       " np.float64(0.4304182000923902),\n",
       " np.float64(9.977568000089377))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the duration of each trial\n",
    "durations = [end - start for start, end in synced_start_end_times]\n",
    "\n",
    "# Calculate the mean and standard deviation of the durations\n",
    "mean_duration = np.mean(durations)\n",
    "std_duration = np.std(durations)\n",
    "\n",
    "min_duration = np.min(durations)\n",
    "max_duration = np.max(durations)\n",
    "\n",
    "mean_duration, std_duration, min_duration, max_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find closest indices in `euler_vels.time` for each trial's start and end time\n",
    "trial_indices = [\n",
    "    (\n",
    "        np.abs(euler_vels.time - start).argmin(),  # Closest index to start time\n",
    "        np.abs(euler_vels.time - end).argmin()     # Closest index to end time\n",
    "    )\n",
    "    for start, end in synced_start_end_times\n",
    "]\n",
    "\n",
    "# Use these indices to slice `euler_vels.time` for each trial\n",
    "trial_segments = [euler_vels.time[start_idx:end_idx+1] for start_idx, end_idx in trial_indices]\n",
    "\n",
    "# Check the first few segments as a sample\n",
    "len(trial_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forearm [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store data for each trial's points\n",
    "Angvel_R_Forearm0 = []\n",
    "\n",
    "# Loop through each trial and extract point 1 and point 2 values\n",
    "for i, (start_idx, end_idx) in enumerate(trial_indices):\n",
    "    # Point 1: 21 indices after start_idx\n",
    "    point1_idx = start_idx + 21 if start_idx + 21 <= end_idx else end_idx\n",
    "    point1_time = euler_vels.time[point1_idx]\n",
    "    point1_value = euler_vels.data[\"R_Forearm\"][point1_idx, 0]\n",
    "    point1_euler = euler.data[\"R_Forearm\"][point1_idx, 0]\n",
    "\n",
    "    \n",
    "    # Point 2: Maximum value in the trial\n",
    "    trial_data = euler_vels.data[\"R_Forearm\"][start_idx:end_idx + 1, 0]\n",
    "    trial_euler = euler.data[\"R_Forearm\"][start_idx:end_idx + 1, 0]\n",
    "    trial_time = euler_vels.time[start_idx:end_idx + 1]\n",
    "    max_idx_in_trial = np.argmax(np.abs(trial_data))\n",
    "    max_time = trial_time[max_idx_in_trial]\n",
    "    max_value = trial_data[max_idx_in_trial]\n",
    "    max_value_euler = trial_euler[max_idx_in_trial]\n",
    "    \n",
    "    # Add data for point 1\n",
    "    Angvel_R_Forearm0.append({\n",
    "        \"Angle Name\": \"R_Forearm[0] move onset\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": point1_time,\n",
    "        \"Value\": point1_value,\n",
    "        \"Euler\": point1_euler\n",
    "    })\n",
    "    \n",
    "    # Add data for point 2\n",
    "    Angvel_R_Forearm0.append({\n",
    "        \"Angle Name\": \"R_Forearm[0] max vel\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": max_time,\n",
    "        \"Value\": max_value,\n",
    "        \"Euler\": max_value_euler\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "Angvel_R_Forearm0 = pd.DataFrame(Angvel_R_Forearm0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "# plt.plot(euler.time, euler.data[\"R_Arm\"],label = \"R_Arm\" )\n",
    "# plt.plot(euler.time, euler.data[\"Thorax\"],label = \"Thorax\" )\n",
    "# plt.plot(euler.time, euler.data[\"Pelvis\"],label = \"Pelvis\")\n",
    "plt.plot(euler.time, np.nan_to_num(euler.data[\"R_Forearm\"]), label=\"R_Forearm\")\n",
    "plt.title('Example Angle')\n",
    "\n",
    "plt.ylabel('deg')\n",
    "plt.legend()\n",
    "# plt.ylim(-100,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# for i, (start_idx, end_idx) in enumerate(trial_indices):\n",
    "#     # Get the absolute data segment for the trial\n",
    "#     trial_data = euler_vels.data[\"R_Forearm\"][start_idx:end_idx + 1, 0]   # Using abs() on the first angle\n",
    "#     trial_time = euler_vels.time[start_idx:end_idx + 1]\n",
    "\n",
    "#     # Set color based on trial range\n",
    "#     if i < 10:\n",
    "#         color = 'grey'  # Familiarization: trials 1–10\n",
    "#         label = 'Familiarization' if i == 0 else \"\"\n",
    "#     elif 310 <= i < 321:\n",
    "#         color = 'black'  # Baseline: trials 11–40\n",
    "#         label = 'Baseline' if i == 10 else \"\"\n",
    "#     else:\n",
    "#         color = 'red'  # Rotation: trials 41–85\n",
    "#         label = 'Rotation' if i == 40 else \"\"\n",
    "\n",
    "#         # Point 1: 60 indices after start_idx 400ms 0.4s\n",
    "#     point1_idx = start_idx + 30 if start_idx + 30 <= end_idx else end_idx\n",
    "#     point1_time = euler_vels.time[point1_idx]\n",
    "#     point1_value = euler_vels.data[\"R_Forearm\"][point1_idx, 0]\n",
    "\n",
    "#     # Point 2: Maximum value in the trial\n",
    "#     max_idx_in_trial = np.argmax(np.abs(trial_data))  # Index relative to trial_data\n",
    "#     max_time = trial_time[max_idx_in_trial]\n",
    "#     max_value = trial_data[max_idx_in_trial]\n",
    "\n",
    "#         # Plot the trial data segment for context\n",
    "#     plt.plot(trial_time, trial_data,  color=color, label=label, alpha=0.5)\n",
    "\n",
    "#     # Plot Point 1\n",
    "#     plt.plot(point1_time, point1_value, 'o', color='blue', label='Move on set 200ms' if i == 0 else \"\")\n",
    "\n",
    "#     # Plot Point 2 (maximum value)\n",
    "#     plt.plot(max_time, max_value, 's', color='red', label='Max Value' if i == 0 else \"\")\n",
    "\n",
    "# # Add labels and legend\n",
    "# plt.ylabel('deg/s (absolute)')\n",
    "# plt.title('Absolute R_Forearm Angle Across Phases')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forearm [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store data for each trial's points\n",
    "Angvel_R_Forearm2 = []\n",
    "\n",
    "# Loop through each trial and extract point 1 and point 2 values\n",
    "for i, (start_idx, end_idx) in enumerate(trial_indices):\n",
    "    # Point 1: 21 indices after start_idx\n",
    "    point1_idx = start_idx + 21 if start_idx + 21 <= end_idx else end_idx\n",
    "    point1_time = euler_vels.time[point1_idx]\n",
    "    point1_value = euler_vels.data[\"R_Forearm\"][point1_idx, 2]\n",
    "    point1_euler = euler.data[\"R_Forearm\"][point1_idx, 2]\n",
    "    \n",
    "    # Point 2: Maximum value in the trial\n",
    "    trial_data = euler_vels.data[\"R_Forearm\"][start_idx:end_idx + 1, 2]\n",
    "    trial_euler = euler.data[\"R_Forearm\"][start_idx:end_idx + 1, 2]\n",
    "    trial_time = euler_vels.time[start_idx:end_idx + 1]\n",
    "    max_idx_in_trial = np.argmax(np.abs(trial_data))\n",
    "    max_time = trial_time[max_idx_in_trial]\n",
    "    max_value = trial_data[max_idx_in_trial]\n",
    "    max_value_euler = trial_euler[max_idx_in_trial]\n",
    "    \n",
    "    # Add data for point 1\n",
    "    Angvel_R_Forearm2.append({\n",
    "        \"Angle Name\": \"R_Forearm[2] move onset\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": point1_time,\n",
    "        \"Value\": point1_value,\n",
    "        \"Euler\": point1_euler\n",
    "    })\n",
    "    \n",
    "    # Add data for point 2\n",
    "    Angvel_R_Forearm2.append({\n",
    "        \"Angle Name\": \"R_Forearm[2] max vel\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": max_time,\n",
    "        \"Value\": max_value,\n",
    "        \"Euler\": max_value_euler\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "Angvel_R_Forearm2 = pd.DataFrame(Angvel_R_Forearm2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store data for each trial's points\n",
    "Angvel_R_Arm1 = []\n",
    "\n",
    "# Loop through each trial and extract point 1 and point 2 values\n",
    "for i, (start_idx, end_idx) in enumerate(trial_indices):\n",
    "    # Point 1: 21 indices after start_idx\n",
    "    point1_idx = start_idx + 21 if start_idx + 21 <= end_idx else end_idx\n",
    "    point1_time = euler_vels.time[point1_idx]\n",
    "    point1_value = euler_vels.data[\"R_Arm\"][point1_idx, 1]\n",
    "    point1_euler = euler.data[\"R_Arm\"][point1_idx, 1]\n",
    "    \n",
    "    # Point 2: Maximum value in the trial\n",
    "    trial_data = euler_vels.data[\"R_Arm\"][start_idx:end_idx + 1, 1]\n",
    "    trial_euler = euler.data[\"R_Arm\"][start_idx:end_idx + 1, 1]\n",
    "    trial_time = euler_vels.time[start_idx:end_idx + 1]\n",
    "    max_idx_in_trial = np.argmax(np.abs(trial_data))\n",
    "    max_time = trial_time[max_idx_in_trial]\n",
    "    max_value = trial_data[max_idx_in_trial]\n",
    "    max_value_euler = trial_euler[max_idx_in_trial]\n",
    "    \n",
    "    # Add data for point 1\n",
    "    Angvel_R_Arm1.append({\n",
    "        \"Angle Name\": \"R_Arm[1] move onset\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": point1_time,\n",
    "        \"Value\": point1_value,\n",
    "        \"Euler\": point1_euler\n",
    "    })\n",
    "    \n",
    "    # Add data for point 2\n",
    "    Angvel_R_Arm1.append({\n",
    "        \"Angle Name\": \"R_Arm[1] max vel\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": max_time,\n",
    "        \"Value\": max_value,\n",
    "        \"Euler\": max_value_euler\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "Angvel_R_Arm1 = pd.DataFrame(Angvel_R_Arm1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arm[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store data for each trial's points\n",
    "Angvel_R_Arm2 = []\n",
    "\n",
    "# Loop through each trial and extract point 1 and point 2 values\n",
    "for i, (start_idx, end_idx) in enumerate(trial_indices):\n",
    "    # Point 1: 21 indices after start_idx\n",
    "    point1_idx = start_idx + 21 if start_idx + 21 <= end_idx else end_idx\n",
    "    point1_time = euler_vels.time[point1_idx]\n",
    "    point1_value = euler_vels.data[\"R_Arm\"][point1_idx, 2]\n",
    "    point1_euler = euler.data[\"R_Arm\"][point1_idx, 2]\n",
    "    \n",
    "    # Point 2: Maximum value in the trial\n",
    "    trial_data = euler_vels.data[\"R_Arm\"][start_idx:end_idx + 1,2]\n",
    "    trial_euler = euler.data[\"R_Arm\"][start_idx:end_idx + 1, 2]\n",
    "    trial_time = euler_vels.time[start_idx:end_idx + 1]\n",
    "    max_idx_in_trial = np.argmax(np.abs(trial_data))\n",
    "    max_time = trial_time[max_idx_in_trial]\n",
    "    max_value = trial_data[max_idx_in_trial]\n",
    "    max_value_euler = trial_euler[max_idx_in_trial]\n",
    "    \n",
    "    # Add data for point 1\n",
    "    Angvel_R_Arm2.append({\n",
    "        \"Angle Name\": \"R_Arm[2] move onset\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": point1_time,\n",
    "        \"Value\": point1_value,\n",
    "        \"Euler\": point1_euler\n",
    "    })\n",
    "    \n",
    "    # Add data for point 2\n",
    "    Angvel_R_Arm2.append({\n",
    "        \"Angle Name\": \"R_Arm[2] max vel\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": max_time,\n",
    "        \"Value\": max_value,\n",
    "        \"Euler\": max_value_euler\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "Angvel_R_Arm2 = pd.DataFrame(Angvel_R_Arm2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store data for each trial's points\n",
    "Angvel_R_Hand1 = []\n",
    "\n",
    "# Loop through each trial and extract point 1 and point 2 values\n",
    "for i, (start_idx, end_idx) in enumerate(trial_indices):\n",
    "    # Point 1: 21 indices after start_idx\n",
    "    point1_idx = start_idx + 21 if start_idx + 21 <= end_idx else end_idx\n",
    "    point1_time = euler_vels.time[point1_idx]\n",
    "    point1_value = euler_vels.data[\"R_Hand\"][point1_idx, 1]\n",
    "    point1_euler = euler.data[\"R_Hand\"][point1_idx, 1]\n",
    "    \n",
    "    # Point 2: Maximum value in the trial\n",
    "    trial_data = euler_vels.data[\"R_Hand\"][start_idx:end_idx + 1,1]\n",
    "    trial_euler = euler.data[\"R_Hand\"][start_idx:end_idx + 1, 1]\n",
    "    trial_time = euler_vels.time[start_idx:end_idx + 1]\n",
    "    max_idx_in_trial = np.argmax(np.abs(trial_data))\n",
    "    max_time = trial_time[max_idx_in_trial]\n",
    "    max_value = trial_data[max_idx_in_trial]\n",
    "    max_value_euler = trial_euler[max_idx_in_trial]\n",
    "    \n",
    "    # Add data for point 1\n",
    "    Angvel_R_Hand1.append({\n",
    "        \"Angle Name\": \"R_Hand[1] move onset\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": point1_time,\n",
    "        \"Value\": point1_value,\n",
    "        \"Euler\": point1_euler\n",
    "    })\n",
    "    \n",
    "    # Add data for point 2\n",
    "    Angvel_R_Hand1.append({\n",
    "        \"Angle Name\": \"R_Hand[1] max vel\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": max_time,\n",
    "        \"Value\": max_value,\n",
    "        \"Euler\": max_value_euler\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "Angvel_R_Hand1 = pd.DataFrame(Angvel_R_Hand1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Throax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store data for each trial's points\n",
    "Angvel_throax0 = []\n",
    "\n",
    "# Loop through each trial and extract point 1 and point 2 values\n",
    "for i, (start_idx, end_idx) in enumerate(trial_indices):\n",
    "    # Point 1: 21 indices after start_idx\n",
    "    point1_idx = start_idx + 21 if start_idx + 21 <= end_idx else end_idx\n",
    "    point1_time = euler_vels.time[point1_idx]\n",
    "    point1_value = euler_vels.data[\"Thorax\"][point1_idx, 0]\n",
    "    point1_euler = euler.data[\"Thorax\"][point1_idx, 0]\n",
    "    \n",
    "    # Point 2: Maximum value in the trial\n",
    "    trial_data = euler_vels.data[\"Thorax\"][start_idx:end_idx + 1,0]\n",
    "    trial_euler = euler.data[\"Thorax\"][start_idx:end_idx + 1, 0]\n",
    "    trial_time = euler_vels.time[start_idx:end_idx + 1]\n",
    "    max_idx_in_trial = np.argmax(np.abs(trial_data))\n",
    "    max_time = trial_time[max_idx_in_trial]\n",
    "    max_value = trial_data[max_idx_in_trial]\n",
    "    max_value_euler = trial_euler[max_idx_in_trial]\n",
    "    \n",
    "    # Add data for point 1\n",
    "    Angvel_throax0.append({\n",
    "        \"Angle Name\": \"Thorax[0] move onset\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": point1_time,\n",
    "        \"Value\": point1_value,\n",
    "        \"Euler\": point1_euler\n",
    "    })\n",
    "    \n",
    "    # Add data for point 2\n",
    "    Angvel_throax0.append({\n",
    "        \"Angle Name\": \"Thorax[0] max vel\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": max_time,\n",
    "        \"Value\": max_value,\n",
    "        \"Euler\": max_value_euler\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "Angvel_throax0 = pd.DataFrame(Angvel_throax0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store data for each trial's points\n",
    "Angvel_throax1 = []\n",
    "\n",
    "# Loop through each trial and extract point 1 and point 2 values\n",
    "for i, (start_idx, end_idx) in enumerate(trial_indices):\n",
    "    # Point 1: 21 indices after start_idx\n",
    "    point1_idx = start_idx + 21 if start_idx + 21 <= end_idx else end_idx\n",
    "    point1_time = euler_vels.time[point1_idx]\n",
    "    point1_value = euler_vels.data[\"Thorax\"][point1_idx, 1]\n",
    "    point1_euler = euler.data[\"Thorax\"][point1_idx, 1]\n",
    "    \n",
    "    # Point 2: Maximum value in the trial\n",
    "    trial_data = euler_vels.data[\"Thorax\"][start_idx:end_idx + 1,1]\n",
    "    trial_euler = euler.data[\"Thorax\"][start_idx:end_idx + 1, 1]\n",
    "    trial_time = euler_vels.time[start_idx:end_idx + 1]\n",
    "    max_idx_in_trial = np.argmax(np.abs(trial_data))\n",
    "    max_time = trial_time[max_idx_in_trial]\n",
    "    max_value = trial_data[max_idx_in_trial]\n",
    "    max_value_euler = trial_euler[max_idx_in_trial]\n",
    "    \n",
    "    \n",
    "    # Add data for point 1\n",
    "    Angvel_throax1.append({\n",
    "        \"Angle Name\": \"Thorax[1] move onset\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": point1_time,\n",
    "        \"Value\": point1_value,\n",
    "        \"Euler\": point1_euler\n",
    "    })\n",
    "    \n",
    "    # Add data for point 2\n",
    "    Angvel_throax1.append({\n",
    "        \"Angle Name\": \"Thorax[1] max vel\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": max_time,\n",
    "        \"Value\": max_value,\n",
    "        \"Euler\": max_value_euler\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "Angvel_throax1 = pd.DataFrame(Angvel_throax1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store data for each trial's points\n",
    "Angvel_throax2 = []\n",
    "\n",
    "# Loop through each trial and extract point 1 and point 2 values\n",
    "for i, (start_idx, end_idx) in enumerate(trial_indices):\n",
    "    # Point 1: 21 indices after start_idx\n",
    "    point1_idx = start_idx + 21 if start_idx + 21 <= end_idx else end_idx\n",
    "    point1_time = euler_vels.time[point1_idx]\n",
    "    point1_value = euler_vels.data[\"Thorax\"][point1_idx, 2]\n",
    "    point1_euler = euler.data[\"Thorax\"][point1_idx, 2]\n",
    "    \n",
    "    # Point 2: Maximum value in the trial\n",
    "    trial_data = euler_vels.data[\"Thorax\"][start_idx:end_idx + 1,2]\n",
    "    trial_euler = euler.data[\"Thorax\"][start_idx:end_idx + 1, 2]\n",
    "    trial_time = euler_vels.time[start_idx:end_idx + 1]\n",
    "    max_idx_in_trial = np.argmax(np.abs(trial_data))\n",
    "    max_time = trial_time[max_idx_in_trial]\n",
    "    max_value = trial_data[max_idx_in_trial]\n",
    "    max_value_euler = trial_euler[max_idx_in_trial]\n",
    "    \n",
    "    \n",
    "    # Add data for point 1\n",
    "    Angvel_throax2.append({\n",
    "        \"Angle Name\": \"Thorax[2] move onset\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": point1_time,\n",
    "        \"Value\": point1_value,\n",
    "        \"Euler\": point1_euler\n",
    "    })\n",
    "    \n",
    "    # Add data for point 2\n",
    "    Angvel_throax2.append({\n",
    "        \"Angle Name\": \"Thorax[2] max vel\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": max_time,\n",
    "        \"Value\": max_value,\n",
    "        \"Euler\": max_value_euler\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "Angvel_throax2 = pd.DataFrame(Angvel_throax2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pelvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store data for each trial's points\n",
    "Angvel_pelvis0 = []\n",
    "\n",
    "# Loop through each trial and extract point 1 and point 2 values\n",
    "for i, (start_idx, end_idx) in enumerate(trial_indices):\n",
    "    # Point 1: 21 indices after start_idx\n",
    "    point1_idx = start_idx + 21 if start_idx + 21 <= end_idx else end_idx\n",
    "    point1_time = euler_vels.time[point1_idx]\n",
    "    point1_value = euler_vels.data[\"Pelvis\"][point1_idx, 0]\n",
    "    point1_euler = euler.data[\"Pelvis\"][point1_idx, 0]\n",
    "    \n",
    "    # Point 2: Maximum value in the trial\n",
    "    trial_data = euler_vels.data[\"Pelvis\"][start_idx:end_idx + 1,0]\n",
    "    trial_euler = euler.data[\"Pelvis\"][start_idx:end_idx + 1, 0]\n",
    "    trial_time = euler_vels.time[start_idx:end_idx + 1]\n",
    "    max_idx_in_trial = np.argmax(np.abs(trial_data))\n",
    "    max_time = trial_time[max_idx_in_trial]\n",
    "    max_value = trial_data[max_idx_in_trial]\n",
    "    max_value_euler = trial_euler[max_idx_in_trial]\n",
    "    \n",
    "    \n",
    "    # Add data for point 1\n",
    "    Angvel_pelvis0.append({\n",
    "        \"Angle Name\": \"Pelvis[0] move onset\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": point1_time,\n",
    "        \"Value\": point1_value,\n",
    "        \"Euler\": point1_euler\n",
    "    })\n",
    "    \n",
    "    # Add data for point 2\n",
    "    Angvel_pelvis0.append({\n",
    "        \"Angle Name\": \"Pelvis[0] max vel\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": max_time,\n",
    "        \"Value\": max_value,\n",
    "        \"Euler\": max_value_euler\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "Angvel_pelvis0 = pd.DataFrame(Angvel_pelvis0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store data for each trial's points\n",
    "Angvel_pelvis1 = []\n",
    "\n",
    "# Loop through each trial and extract point 1 and point 2 values\n",
    "for i, (start_idx, end_idx) in enumerate(trial_indices):\n",
    "    # Point 1: 21 indices after start_idx\n",
    "    point1_idx = start_idx + 21 if start_idx + 21 <= end_idx else end_idx\n",
    "    point1_time = euler_vels.time[point1_idx]\n",
    "    point1_value = euler_vels.data[\"Pelvis\"][point1_idx, 1]\n",
    "    point1_euler = euler.data[\"Pelvis\"][point1_idx, 1]\n",
    "    \n",
    "    # Point 2: Maximum value in the trial\n",
    "    trial_data = euler_vels.data[\"Pelvis\"][start_idx:end_idx + 1,1]\n",
    "    trial_euler = euler.data[\"Pelvis\"][start_idx:end_idx + 1,1]\n",
    "    trial_time = euler_vels.time[start_idx:end_idx + 1]\n",
    "    max_idx_in_trial = np.argmax(np.abs(trial_data))\n",
    "    max_time = trial_time[max_idx_in_trial]\n",
    "    max_value = trial_data[max_idx_in_trial]\n",
    "    max_value_euler = trial_euler[max_idx_in_trial]\n",
    "    # Add data for point 1\n",
    "    Angvel_pelvis1.append({\n",
    "        \"Angle Name\": \"Pelvis[1] move onset\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": point1_time,\n",
    "        \"Value\": point1_value,\n",
    "        \"Euler\": point1_euler\n",
    "    })\n",
    "    \n",
    "    # Add data for point 2\n",
    "    Angvel_pelvis1.append({\n",
    "        \"Angle Name\": \"Pelvis[1] max vel\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": max_time,\n",
    "        \"Value\": max_value,\n",
    "        \"Euler\": max_value_euler\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "Angvel_pelvis1 = pd.DataFrame(Angvel_pelvis1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store data for each trial's points\n",
    "Angvel_pelvis2 = []\n",
    "\n",
    "# Loop through each trial and extract point 1 and point 2 values\n",
    "for i, (start_idx, end_idx) in enumerate(trial_indices):\n",
    "    # Point 1: 21 indices after start_idx\n",
    "    point1_idx = start_idx + 21 if start_idx + 21 <= end_idx else end_idx\n",
    "    point1_time = euler_vels.time[point1_idx]\n",
    "    point1_value = euler_vels.data[\"Pelvis\"][point1_idx, 2]\n",
    "    point1_euler = euler.data[\"Pelvis\"][point1_idx, 2]\n",
    "    \n",
    "    # Point 2: Maximum value in the trial\n",
    "    trial_data = euler_vels.data[\"Pelvis\"][start_idx:end_idx + 1,2]\n",
    "    trial_euler = euler.data[\"Pelvis\"][start_idx:end_idx + 1, 2]\n",
    "    trial_time = euler_vels.time[start_idx:end_idx + 1]\n",
    "    max_idx_in_trial = np.argmax(np.abs(trial_data))\n",
    "    max_time = trial_time[max_idx_in_trial]\n",
    "    max_value = trial_data[max_idx_in_trial]\n",
    "    max_value_euler = trial_euler[max_idx_in_trial]\n",
    "    \n",
    "    # Add data for point 1\n",
    "    Angvel_pelvis2.append({\n",
    "        \"Angle Name\": \"Pelvis[2] move onset\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": point1_time,\n",
    "        \"Value\": point1_value,\n",
    "        \"Euler\": point1_euler\n",
    "    })\n",
    "    \n",
    "    # Add data for point 2\n",
    "    Angvel_pelvis2.append({\n",
    "        \"Angle Name\": \"Pelvis[2] max vel\",\n",
    "        \"Trial ID\": i + 1,\n",
    "        \"Time\": max_time,\n",
    "        \"Value\": max_value,\n",
    "        \"Euler\": max_value_euler\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "Angvel_pelvis2 = pd.DataFrame(Angvel_pelvis2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DataFrames\n",
    "all_joints_list = [\n",
    "    Angvel_R_Forearm0, Angvel_R_Forearm2, Angvel_R_Arm1, Angvel_R_Arm2,\n",
    "    Angvel_R_Hand1, Angvel_throax0, Angvel_throax1, Angvel_throax2,\n",
    "    Angvel_pelvis0, Angvel_pelvis1, Angvel_pelvis2\n",
    "]\n",
    "\n",
    "# Concatenate all data frames\n",
    "all_joints_df = pd.concat(all_joints_list, ignore_index=True)\n",
    "\n",
    "# Ensure the data is sorted by 'Trial ID'\n",
    "all_joints_df = all_joints_df.sort_values(by=[\"Trial ID\", \"Angle Name\"]).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rotation_data_early = all_joints_df[(all_joints_df['Trial ID'] >= 11) & (all_joints_df['Trial ID'] <= 110)]\n",
    "Rotation_data_late = all_joints_df[(all_joints_df['Trial ID'] >= 211) & (all_joints_df['Trial ID'] <= 310)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create pivot tables\n",
    "early_value_data = Rotation_data_early.pivot_table(index='Trial ID', columns='Angle Name', values='Value')\n",
    "early_euler_data = Rotation_data_early.pivot_table(index='Trial ID', columns='Angle Name', values='Euler')\n",
    "\n",
    "# Step 2: Combine the two DataFrames into one\n",
    "early_data = pd.concat([early_value_data, early_euler_data], axis=1)\n",
    "\n",
    "# Step 3: Rename the columns for clarity\n",
    "# Create new column names for Value and Euler\n",
    "value_columns = [f\"{angle}_Value\" for angle in early_value_data.columns]\n",
    "euler_columns = [f\"{angle}_Euler\" for angle in early_euler_data.columns]\n",
    "\n",
    "# Assign the new column names\n",
    "early_data.columns = value_columns + euler_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_cov_matrix = early_data.cov()\n",
    "early_det_value = np.linalg.det(early_cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create pivot tables\n",
    "late_value_data = Rotation_data_late.pivot_table(index='Trial ID', columns='Angle Name', values='Value')\n",
    "late_euler_data = Rotation_data_late.pivot_table(index='Trial ID', columns='Angle Name', values='Euler')\n",
    "\n",
    "# Step 2: Combine the two DataFrames into one\n",
    "late_data = pd.concat([late_value_data, late_euler_data], axis=1)\n",
    "\n",
    "# Step 3: Rename the columns for clarity\n",
    "# Create new column names for Value and Euler\n",
    "value_columns = [f\"{angle}_Value\" for angle in late_value_data.columns]\n",
    "euler_columns = [f\"{angle}_Euler\" for angle in late_euler_data.columns]\n",
    "\n",
    "# Assign the new column names\n",
    "late_data.columns = value_columns + euler_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_cov_matrix = late_data.cov()\n",
    "late_det_value = np.linalg.det(late_cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9.312548802432506e+44)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_det_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.9516510658055335e+42)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_det_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyOPLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming SRdata is your DataFrame\n",
    "# Initialize variables to store trial count and start/end times\n",
    "trial_count = 0\n",
    "Endx = []\n",
    "Endy = []\n",
    "\n",
    "# Iterate through each row in the 'moving_mouse.time' column\n",
    "for i, row in Subject01_SRdata['moving_mouse.x'].items():\n",
    "    if pd.notna(row):\n",
    "        # Increment trial count\n",
    "        trial_count += 1\n",
    "        \n",
    "        # Convert the row to a list and get the first and last element\n",
    "        time_series = eval(row)  # Using eval to convert string representation of lists to actual lists\n",
    "        endM_x= time_series[-1]\n",
    "        \n",
    "        # Store the start and end times\n",
    "        Endx.append((endM_x))\n",
    "\n",
    "# Iterate through each row in the 'moving_mouse.time' column\n",
    "for i, row in Subject01_SRdata['moving_mouse.y'].items():\n",
    "    if pd.notna(row):\n",
    "        # Increment trial count\n",
    "        trial_count += 1\n",
    "        \n",
    "        # Convert the row to a list and get the first and last element\n",
    "        time_series = eval(row)  # Using eval to convert string representation of lists to actual lists\n",
    "        endM_y= time_series[-1]\n",
    "        \n",
    "        # Store the start and end times\n",
    "        Endy.append((endM_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the angle for each (x, y) pair\n",
    "angles = np.arctan2(Endy, Endx)\n",
    "\n",
    "# Optionally, convert from radians to degrees\n",
    "angles_degrees = np.degrees(angles)\n",
    "\n",
    "rotation_angles = angles_degrees-60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the elements from index 11 to 110 for early_angerror\n",
    "early_angerror = rotation_angles[10:110]\n",
    "\n",
    "# Select the elements from index 210 to 310 for end_angerror\n",
    "late_angerror = rotation_angles[210:310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from pyopls import OPLS\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneOut\n",
    "from sklearn.metrics import r2_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 44)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does early_data contain NaN values? False\n",
      "Rows containing NaN values:\n",
      "Empty DataFrame\n",
      "Columns: [Pelvis[0] max vel_Value, Pelvis[0] move onset_Value, Pelvis[1] max vel_Value, Pelvis[1] move onset_Value, Pelvis[2] max vel_Value, Pelvis[2] move onset_Value, R_Arm[1] max vel_Value, R_Arm[1] move onset_Value, R_Arm[2] max vel_Value, R_Arm[2] move onset_Value, R_Forearm[0] max vel_Value, R_Forearm[0] move onset_Value, R_Forearm[2] max vel_Value, R_Forearm[2] move onset_Value, R_Hand[1] max vel_Value, R_Hand[1] move onset_Value, Thorax[0] max vel_Value, Thorax[0] move onset_Value, Thorax[1] max vel_Value, Thorax[1] move onset_Value, Thorax[2] max vel_Value, Thorax[2] move onset_Value, Pelvis[0] max vel_Euler, Pelvis[0] move onset_Euler, Pelvis[1] max vel_Euler, Pelvis[1] move onset_Euler, Pelvis[2] max vel_Euler, Pelvis[2] move onset_Euler, R_Arm[1] max vel_Euler, R_Arm[1] move onset_Euler, R_Arm[2] max vel_Euler, R_Arm[2] move onset_Euler, R_Forearm[0] max vel_Euler, R_Forearm[0] move onset_Euler, R_Forearm[2] max vel_Euler, R_Forearm[2] move onset_Euler, R_Hand[1] max vel_Euler, R_Hand[1] move onset_Euler, Thorax[0] max vel_Euler, Thorax[0] move onset_Euler, Thorax[1] max vel_Euler, Thorax[1] move onset_Euler, Thorax[2] max vel_Euler, Thorax[2] move onset_Euler]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "has_nan = early_data.isna().any().any()\n",
    "print(\"Does early_data contain NaN values?\", has_nan)\n",
    "nan_rows = early_data[early_data.isna().any(axis=1)]\n",
    "print(\"Rows containing NaN values:\")\n",
    "print(nan_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_angerror.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward-fill rows with NaNs based on the previous row\n",
    "early_data = early_data.ffill(axis=0)\n",
    "\n",
    "# Check if there are still any NaNs remaining in the first row\n",
    "# If the first row has NaNs, they will remain as there is no previous row to copy from\n",
    "early_data.iloc[0] = early_data.iloc[0].fillna(early_data.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "opls = OPLS(20)\n",
    "self = opls.fit(early_data,early_angerror)\n",
    "TP = self.T_ortho_ @ np.transpose(self.P_ortho_)\n",
    "early_reduandant_cov_matrix = np.cov(TP)\n",
    "early_reduandant_det_value = np.linalg.det(early_reduandant_cov_matrix)\n",
    "Z = opls.transform(early_data)\n",
    "\n",
    "early_related_cov_matrix = np.cov(Z)\n",
    "early_related_det_value = np.linalg.det(early_related_cov_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.27534324595724785),\n",
       " np.float64(-0.8516539711713791),\n",
       " np.float64(3.9136046014621333))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean_duration = np.mean(early_reduandant_cov_matrix)\n",
    "# mean_value = early_reduandant_cov_matrix.mean()\n",
    "std_duration = np.std(early_reduandant_cov_matrix)\n",
    "\n",
    "min_duration = np.min(early_reduandant_cov_matrix)\n",
    "max_duration = np.max(early_reduandant_cov_matrix)\n",
    "\n",
    "\n",
    "std_duration,min_duration,max_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.0)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_reduandant_det_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_related_det_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeWarning [C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_17396\\602075590.py:1] invalid value encountered in scalar divide\n"
     ]
    }
   ],
   "source": [
    "efficiency = early_reduandant_det_value / early_related_det_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(nan)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficiency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective pseudo-determinant: 27.92418306772827\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.linalg import svd\n",
    "\n",
    "def effective_pseudo_determinant(matrix, threshold=1e-10):\n",
    "    \"\"\"\n",
    "    Calculate the pseudo-determinant of a matrix based on its effective rank.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix (np.ndarray): The input matrix.\n",
    "    threshold (float): Threshold for considering singular values as non-zero.\n",
    "    \n",
    "    Returns:\n",
    "    float: The pseudo-determinant based on effective rank.\n",
    "    \"\"\"\n",
    "    # Compute singular values\n",
    "    u, s, vh = svd(matrix)\n",
    "    \n",
    "    # Filter singular values by threshold to determine effective rank\n",
    "    effective_singular_values = s[s > threshold]\n",
    "    \n",
    "    # Compute pseudo-determinant as the product of these singular values\n",
    "    pseudo_det = np.prod(effective_singular_values)\n",
    "    \n",
    "    return pseudo_det\n",
    "\n",
    "# Example usage:\n",
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9],[0,2,0.2]])  # Example matrix (rank-deficient)\n",
    "pseudo_det = effective_pseudo_determinant(A, threshold=1e-5)\n",
    "print(\"Effective pseudo-determinant:\", pseudo_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_det = effective_pseudo_determinant(early_reduandant_cov_matrix, threshold=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7181707.298423651)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_det_related = effective_pseudo_determinant(early_related_cov_matrix, threshold=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0018842672125204162)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_det_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3811405967.637319)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_efficiency  = pseudo_det/pseudo_det_related\n",
    "pseudo_efficiency \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.2509457677808296e+54)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_early_cov_matrix = effective_pseudo_determinant(early_cov_matrix, threshold=1e-1)\n",
    "pseudo_early_cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(13532.25559233826)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_det*pseudo_det_related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does late_data contain NaN values? False\n",
      "Rows containing NaN values:\n",
      "Empty DataFrame\n",
      "Columns: [Pelvis[0] max vel_Value, Pelvis[0] move onset_Value, Pelvis[1] max vel_Value, Pelvis[1] move onset_Value, Pelvis[2] max vel_Value, Pelvis[2] move onset_Value, R_Arm[1] max vel_Value, R_Arm[1] move onset_Value, R_Arm[2] max vel_Value, R_Arm[2] move onset_Value, R_Forearm[0] max vel_Value, R_Forearm[0] move onset_Value, R_Forearm[2] max vel_Value, R_Forearm[2] move onset_Value, R_Hand[1] max vel_Value, R_Hand[1] move onset_Value, Thorax[0] max vel_Value, Thorax[0] move onset_Value, Thorax[1] max vel_Value, Thorax[1] move onset_Value, Thorax[2] max vel_Value, Thorax[2] move onset_Value, Pelvis[0] max vel_Euler, Pelvis[0] move onset_Euler, Pelvis[1] max vel_Euler, Pelvis[1] move onset_Euler, Pelvis[2] max vel_Euler, Pelvis[2] move onset_Euler, R_Arm[1] max vel_Euler, R_Arm[1] move onset_Euler, R_Arm[2] max vel_Euler, R_Arm[2] move onset_Euler, R_Forearm[0] max vel_Euler, R_Forearm[0] move onset_Euler, R_Forearm[2] max vel_Euler, R_Forearm[2] move onset_Euler, R_Hand[1] max vel_Euler, R_Hand[1] move onset_Euler, Thorax[0] max vel_Euler, Thorax[0] move onset_Euler, Thorax[1] max vel_Euler, Thorax[1] move onset_Euler, Thorax[2] max vel_Euler, Thorax[2] move onset_Euler]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "has_nan = late_data.isna().any().any()\n",
    "print(\"Does late_data contain NaN values?\", has_nan)\n",
    "nan_rows = late_data[late_data.isna().any(axis=1)]\n",
    "print(\"Rows containing NaN values:\")\n",
    "print(nan_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward-fill rows with NaNs based on the previous row\n",
    "late_data = late_data.ffill(axis=0)\n",
    "\n",
    "# Check if there are still any NaNs remaining in the first row\n",
    "# If the first row has NaNs, they will remain as there is no previous row to copy from\n",
    "late_data.iloc[0] = late_data.iloc[0].fillna(late_data.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "opls = OPLS(20)\n",
    "\n",
    "self = opls.fit(late_data,late_angerror)\n",
    "TP = self.T_ortho_ @ np.transpose(self.P_ortho_)\n",
    "late_reduandant_cov_matrix = np.cov(TP)\n",
    "late_reduandant_det_value = np.linalg.det(early_reduandant_cov_matrix)\n",
    "Z = opls.transform(late_data)\n",
    "\n",
    "late_related_cov_matrix = np.cov(Z)\n",
    "late_related_det_value = np.linalg.det(late_related_cov_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7685128.803830537)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_det_late = effective_pseudo_determinant(late_reduandant_cov_matrix, threshold=1e-1)\n",
    "pseudo_det_late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0026203593681432946)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_det_related_late = effective_pseudo_determinant(late_related_cov_matrix, threshold=1e-1)\n",
    "pseudo_det_related_late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2932852988.510496)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_efficiency_late  = pseudo_det_late/pseudo_det_related_late\n",
    "pseudo_efficiency_late "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.583246169734779e+52)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_late_cov_matrix = effective_pseudo_determinant(late_cov_matrix, threshold=1e-1)\n",
    "pseudo_late_cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(20137.79925650522)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_det_late*pseudo_det_related_late"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movement complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PCs needed to explain 90% of variance: 4\n",
      "Number of PCs that explain more than 1% of variance: 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Perform PCA\n",
    "pca_early = PCA()\n",
    "pca_early.fit(early_data)\n",
    "\n",
    "# Calculate explained variance ratio for each component\n",
    "early_explained_variance_ratio = pca_early.explained_variance_ratio_\n",
    "\n",
    "# Determine number of PCs needed to explain 90% of variance\n",
    "early_cumulative_variance = np.cumsum(early_explained_variance_ratio)\n",
    "early_num_pcs_90 = np.argmax(early_cumulative_variance >= 0.90) + 1\n",
    "\n",
    "# Count how many PCs explain more than 1% of variance\n",
    "early_num_pcs_above_1_percent = np.sum(early_explained_variance_ratio > 0.01)\n",
    "\n",
    "print(f\"Number of PCs needed to explain 90% of variance: {early_num_pcs_90}\")\n",
    "print(f\"Number of PCs that explain more than 1% of variance: {early_num_pcs_above_1_percent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PCs needed to explain 90% of variance: 3\n",
      "Number of PCs that explain more than 1% of variance: 7\n"
     ]
    }
   ],
   "source": [
    "# Perform PCA\n",
    "pca_late = PCA()\n",
    "pca_late.fit(late_data)\n",
    "\n",
    "# Calculate explained variance ratio for each component\n",
    "late_explained_variance_ratio = pca_late.explained_variance_ratio_\n",
    "\n",
    "# Determine number of PCs needed to explain 90% of variance\n",
    "late_cumulative_variance = np.cumsum(late_explained_variance_ratio)\n",
    "late_num_pcs_90 = np.argmax(late_cumulative_variance >= 0.90) + 1\n",
    "\n",
    "# Count how many PCs explain more than 1% of variance\n",
    "late_num_pcs_above_1_percent = np.sum(late_explained_variance_ratio > 0.01)\n",
    "\n",
    "print(f\"Number of PCs needed to explain 90% of variance: {late_num_pcs_90}\")\n",
    "print(f\"Number of PCs that explain more than 1% of variance: {late_num_pcs_above_1_percent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming early_angerror and late_angerror are arrays or lists with 100 elements each.\n",
    "# Replace `x_values` with your actual x-coordinates if they are defined. If you just want indices as x-values:\n",
    "x_values = range(100)\n",
    "\n",
    "# Scatter plot for early_angerror\n",
    "plt.scatter(x_values, early_angerror, label=\"Early Angle Error\", color='blue')\n",
    "\n",
    "# Scatter plot for late_angerror\n",
    "plt.scatter(x_values, late_angerror, label=\"Late Angle Error\", color='red')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Angle Error\")\n",
    "plt.title(\"Scatter Plot of Early and Late Angle Errors\")\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2509457677808296e+54 2.583246169734779e+52\n"
     ]
    }
   ],
   "source": [
    "print(pseudo_early_cov_matrix,pseudo_late_cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811405967.637319 2932852988.510496\n"
     ]
    }
   ],
   "source": [
    "print(pseudo_efficiency, pseudo_efficiency_late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Efficiency in the early rotation using Pseudo-Determinant : 3811405967.637319\n",
      "The Efficiency in the late rotation using Pseudo-Determinant : 2932852988.510496\n",
      "Number of PCs needed to explain 90% of variance - early: 4\n",
      "Number of PCs that explain more than 1% of variance - early: 7\n",
      "Number of PCs needed to explain 90% of variance - late: 3\n",
      "Number of PCs that explain more than 1% of variance - late: 7\n"
     ]
    }
   ],
   "source": [
    "# print(f\"The genearal variance in the early rotation : {early_det_value}\")\n",
    "# print(f\"The genearal variance in the late rotation : {late_det_value}\")\n",
    "\n",
    "# print(f\"The genearal variance in the early rotation using Pseudo-Determinant: {pseudo_early_cov_matrix}\")\n",
    "# print(f\"The genearal variance in the late rotation using Pseudo-Determinant : {pseudo_late_cov_matrix}\")\n",
    "\n",
    "print(f\"The Efficiency in the early rotation using Pseudo-Determinant : {pseudo_efficiency}\")\n",
    "print(f\"The Efficiency in the late rotation using Pseudo-Determinant : {pseudo_efficiency_late}\")\n",
    "\n",
    "print(f\"Number of PCs needed to explain 90% of variance - early: {early_num_pcs_90}\")\n",
    "print(f\"Number of PCs that explain more than 1% of variance - early: {early_num_pcs_above_1_percent}\")\n",
    "\n",
    "print(f\"Number of PCs needed to explain 90% of variance - late: {late_num_pcs_90}\")\n",
    "print(f\"Number of PCs that explain more than 1% of variance - late: {late_num_pcs_above_1_percent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Subject01_rotation_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Create a dictionary with the parameters\n",
    "data = {\n",
    "    'early_det_value': early_det_value,\n",
    "    'late_det_value': late_det_value,\n",
    "    'pseudo_early_cov_matrix': pseudo_early_cov_matrix,\n",
    "    'pseudo_late_cov_matrix': pseudo_late_cov_matrix,\n",
    "    'pseudo_efficiency': pseudo_efficiency,\n",
    "    'pseudo_efficiency_late': pseudo_efficiency_late,\n",
    "    'early_num_pcs_90': early_num_pcs_90,\n",
    "    'early_num_pcs_above_1_percent': early_num_pcs_above_1_percent,\n",
    "    'late_num_pcs_90': late_num_pcs_90,\n",
    "    'late_num_pcs_above_1_percent': late_num_pcs_above_1_percent\n",
    "}\n",
    "\n",
    "# Define the filename\n",
    "filename = 'Subject01_rotation_analysis.csv'\n",
    "\n",
    "# Write the data to the CSV file\n",
    "with open(filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(data.keys())  # Write header\n",
    "    writer.writerow(data.values())  # Write values\n",
    "\n",
    "print(f\"Data saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file to store the early data\n",
    "Subejct01_alljoints_path = os.path.join('C:/Users/86153/Desktop/MCSRsystem/SetupV2/exampleplots/', \"Subejct01_all_joints_df.csv\")\n",
    "# Save the all_fish_df to the CSV file\n",
    "all_joints_df.to_csv(Subejct01_alljoints_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_angles_df = pd.DataFrame(rotation_angles)\n",
    "rotation_angles_path = os.path.join('C:/Users/86153/Desktop/MCSRsystem/SetupV2/exampleplots/', \"Subejct01_angerror_df.csv\")\n",
    "rotation_angles_df.to_csv(rotation_angles_path,index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for the num_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# opls = OPLS(10)\n",
    "# self = opls.fit(early_data,early_angerror)\n",
    "# TP = self.T_ortho_ @ np.transpose(self.P_ortho_)\n",
    "# early_reduandant_cov_matrix = np.cov(TP)\n",
    "# early_reduandant_det_value = np.linalg.det(early_reduandant_cov_matrix)\n",
    "# Z = opls.transform(early_data)\n",
    "# early_related_cov_matrix = np.cov(Z)\n",
    "# early_related_det_value = np.linalg.det(early_related_cov_matrix)\n",
    "# pseudo_det = effective_pseudo_determinant(early_reduandant_cov_matrix, threshold=1e-1)\n",
    "# pseudo_det_related = effective_pseudo_determinant(early_related_cov_matrix, threshold=1e-1)\n",
    "# pseudo_efficiency  = pseudo_det/pseudo_det_related\n",
    "# pseudo_early_cov_matrix = effective_pseudo_determinant(early_cov_matrix, threshold=1e-1)\n",
    "\n",
    "\n",
    "\n",
    "# opls = OPLS(10)\n",
    "# self = opls.fit(late_data,late_angerror)\n",
    "# TP = self.T_ortho_ @ np.transpose(self.P_ortho_)\n",
    "# late_reduandant_cov_matrix = np.cov(TP)\n",
    "# late_reduandant_det_value = np.linalg.det(early_reduandant_cov_matrix)\n",
    "# Z = opls.transform(late_data)\n",
    "# late_related_cov_matrix = np.cov(Z)\n",
    "# late_related_det_value = np.linalg.det(late_related_cov_matrix)\n",
    "# pseudo_det_late = effective_pseudo_determinant(late_reduandant_cov_matrix, threshold=1e-1)\n",
    "# pseudo_efficiency_late  = pseudo_det_late/pseudo_det_related_late\n",
    "# pseudo_det_related_late = effective_pseudo_determinant(late_related_cov_matrix, threshold=1e-1)\n",
    "# pseudo_late_cov_matrix = effective_pseudo_determinant(late_cov_matrix, threshold=1e-1)\n",
    "\n",
    "# print(f\"The genearal variance in the early rotation using Pseudo-Determinant: {pseudo_early_cov_matrix}\")\n",
    "# print(f\"The genearal variance in the late rotation using Pseudo-Determinant : {pseudo_late_cov_matrix}\")\n",
    "\n",
    "# print(f\"The Efficiency in the early rotation using Pseudo-Determinant : {pseudo_efficiency}\")\n",
    "# print(f\"The Efficiency in the late rotation using Pseudo-Determinant : {pseudo_efficiency_late}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of input values for OPLS\n",
    "opls_inputs = range(5, 41)\n",
    "\n",
    "# Empty lists to store the results for each opls input\n",
    "early_pseudo_det_values = []\n",
    "late_pseudo_det_values = []\n",
    "early_efficiency_values = []\n",
    "late_efficiency_values = []\n",
    "\n",
    "# Loop through each opls input value\n",
    "for n_components in opls_inputs:\n",
    "    # Initialize and fit OPLS model for early data\n",
    "    opls_early = OPLS(n_components)\n",
    "    self_early = opls_early.fit(early_data, early_angerror)\n",
    "    TP_early = self_early.T_ortho_ @ np.transpose(self_early.P_ortho_)\n",
    "    early_redundant_cov_matrix = np.cov(TP_early)\n",
    "    \n",
    "    Z_early = opls_early.transform(early_data)\n",
    "    early_related_cov_matrix = np.cov(Z_early)\n",
    "    \n",
    "    # Compute pseudo-determinants and efficiency for early data\n",
    "    pseudo_det_early_redundant = effective_pseudo_determinant(early_redundant_cov_matrix, threshold=1e-1)\n",
    "    pseudo_det_early_related = effective_pseudo_determinant(early_related_cov_matrix, threshold=1e-1)\n",
    "    pseudo_efficiency_early = pseudo_det_early_redundant / pseudo_det_early_related\n",
    "    pseudo_early_cov_matrix = effective_pseudo_determinant(early_cov_matrix, threshold=1e-1)\n",
    "    \n",
    "    # Store the results for early data\n",
    "    early_efficiency_values.append(pseudo_efficiency_early)\n",
    "\n",
    "    # Initialize and fit OPLS model for late data\n",
    "    opls_late = OPLS(n_components)\n",
    "    self_late = opls_late.fit(late_data, late_angerror)\n",
    "    TP_late = self_late.T_ortho_ @ np.transpose(self_late.P_ortho_)\n",
    "    late_redundant_cov_matrix = np.cov(TP_late)\n",
    "    \n",
    "    Z_late = opls_late.transform(late_data)\n",
    "    late_related_cov_matrix = np.cov(Z_late)\n",
    "    \n",
    "    # Compute pseudo-determinants and efficiency for late data\n",
    "    pseudo_det_late_redundant = effective_pseudo_determinant(late_redundant_cov_matrix, threshold=1e-1)\n",
    "    pseudo_det_late_related = effective_pseudo_determinant(late_related_cov_matrix, threshold=1e-1)\n",
    "    pseudo_efficiency_late = pseudo_det_late_redundant / pseudo_det_late_related\n",
    "    pseudo_late_cov_matrix = effective_pseudo_determinant(late_cov_matrix, threshold=1e-1)\n",
    "    \n",
    "    # Store the results for late data\n",
    "    late_efficiency_values.append(pseudo_efficiency_late)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPLS Components   | Early Efficiency   | Late Efficiency\n",
      "5                | 374.7139682624249 | 823.5118676570173\n",
      "6                | 4324.589579323188 | 9595.29192680838\n",
      "7                | 41979.10979960389 | 424117.6842133787\n",
      "8                | 193603.65698887553 | 1456305.7264347267\n",
      "9                | 293185.1921620506 | 9741910.63631922\n",
      "10               | 13791769.208351051 | 32846239.954426482\n",
      "11               | 35022511.765134715 | 69078274.28146312\n",
      "12               | 65989725.786085166 | 487012128.9884738\n",
      "13               | 152795503.24758956 | 799611769.7974821\n",
      "14               | 238601929.43347704 | 729758373.0826308\n",
      "15               | 520356107.24929893 | 637717810.0752219\n",
      "16               | 740566457.2032137 | 1168679406.2643082\n",
      "17               | 443754030.6221066 | 7726334955.258456\n",
      "18               | 387380774.9212312 | 3723031378.520125\n",
      "19               | 391348196.77161545 | 2954917530.40068\n",
      "20               | 3811405967.637319 | 2932852988.510496\n",
      "21               | 2873258026.401506 | 15803121041.74155\n",
      "22               | 1172069103.5471156 | 13323240286.75956\n",
      "23               | 5049543364.255398 | 4850973625.051827\n",
      "24               | 1321465852.666681 | 13747854792.149137\n",
      "25               | 422744982.8670142 | 7203101918.851514\n",
      "26               | 226467070.1936522 | 3406059744.6481256\n",
      "27               | 512698851.907561 | 1239331242.0073764\n",
      "28               | 102281052.0963783 | 1279938623.6641405\n",
      "29               | 95046177.34815027 | 1032878070.199515\n",
      "30               | 23863616.60257441 | 251221918.68657908\n",
      "31               | 18554300.817314222 | 131263399.28206739\n",
      "32               | 1420788.0227495641 | 91947562.08103585\n",
      "33               | 2487375.336106915 | 21238257.417159576\n",
      "34               | 328403.35009158746 | 93796486.29327698\n",
      "35               | 13660.206237493025 | 1859188.1791928299\n",
      "36               | 81263.04737037819 | 4880759.871037599\n",
      "37               | 2474.118897611409 | 2239823.9144006083\n",
      "38               | 2527.316055335202 | 319246.9486292845\n",
      "39               | 2555.2510886952373 | 390639.1618453017\n",
      "40               | 2572.3882094925293 | 9319.218491965268\n"
     ]
    }
   ],
   "source": [
    "# Print the results in a table format\n",
    "print(\"OPLS Components   | Early Efficiency   | Late Efficiency\")\n",
    "for i, n in enumerate(opls_inputs):\n",
    "    print(f\"{n:<16} | {early_efficiency_values[i]:<16} | {late_efficiency_values[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the efficiencies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(opls_inputs, early_efficiency_values, label=\"Early Efficiency\", marker='o')\n",
    "plt.plot(opls_inputs, late_efficiency_values, label=\"Late Efficiency\", marker='s')\n",
    "\n",
    "# Labeling the plot\n",
    "plt.xlabel(\"OPLS Components\")\n",
    "plt.ylabel(\"Efficiency\")\n",
    "plt.title(\"Efficiency vs. OPLS Components\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
